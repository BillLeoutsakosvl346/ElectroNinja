# electroninja/llm/vision.py

import os
import base64
from dotenv import load_dotenv
import openai

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
openai.api_key = OPENAI_API_KEY

class VisionManager:
    """
    Manages vision-based interactions with an OpenAI model that supports image inputs.
    Example usage: checking if a generated circuit image matches the user's request.
    """

    def __init__(self, model: str = "gpt-4o-mini"):
        """
        :param model: An OpenAI model that supports vision, e.g. 'gpt-4o-mini', 'gpt-4o', 'o1', etc.
        """
        self.model = model

    def analyze_circuit_image(self, image_path: str, user_request: str, detail: str = "high") -> str:
        """
        Given a circuit screenshot (PNG) and the user's original circuit request,
        ask the model whether the circuit image seems to fulfill the request.

        :param image_path: File path to the circuit screenshot (PNG) generated by LTSpice.
        :param user_request: The text of the user's circuit requirements.
        :param detail: The detail level for image analysis ('low', 'high', or 'auto').
        :return: The model's response as a string.
        """
        # 1. Base64-encode the image
        with open(image_path, "rb") as img_file:
            encoded_image = base64.b64encode(img_file.read()).decode("utf-8")

        # 2. Build the messages array for the Chat Completions API
        messages = [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": (
                            f"User's circuit request: {user_request}\n\n"
                            "Below is an image of the circuit. "
                            "Does this circuit image match the user's request? "
                            "Please analyze carefully and explain."
                        )
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{encoded_image}",
                            "detail": detail
                        }
                    }
                ]
            }
        ]

        # 3. Call the OpenAI Chat Completions endpoint
        try:
            response = openai.ChatCompletion.create(
                model=self.model,
                messages=messages,
                max_tokens=1000,
                temperature=0.2,  # tweak as needed
                store=True
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            return f"Error analyzing circuit image: {str(e)}"
